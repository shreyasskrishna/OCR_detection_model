# ğŸš€ OCR Model Conversion: GPU to CPU ğŸ–¥ï¸ğŸ”„

Welcome to the mini project where I explored the **conversion of an OCR (Optical Character Recognition) model from GPU to CPU**. This project dives into performance comparisons between different hardware setups to evaluate the **efficiency of OCR tasks**.

---

## ğŸ” Project Overview

This project is aimed at understanding how OCR model performance varies between **GPU and CPU executions**. It involves:

- ğŸ”„ Converting a GPU-accelerated OCR model to run on CPU
- ğŸ§  Analyzing **frame-per-second (FPS)** metrics
- ğŸ“Š Comparing **processed frames per second**
- ğŸ”§ Gaining insights into **hardware optimization** for real-world ML applications

---

## ğŸ“Œ Key Highlights

- âœ… **Investigated OCR model performance** on both GPU and CPU
- âš™ï¸ **Compared FPS** and frame processing speeds across hardware
- ğŸ“ˆ Documented findings to highlight real-time efficiency differences
- ğŸ§ª Enhanced practical knowledge in **hardware-aware model deployment**

---

## ğŸ’¡ Why This Matters

Understanding the performance gap between CPU and GPU execution for OCR models is essential for:

- ğŸš€ Optimizing real-time applications
- ğŸ’» Deploying models on devices with limited hardware (e.g., edge devices)
- ğŸ“¦ Making informed decisions during **model deployment and scaling**

---

## ğŸ› ï¸ Tech Stack

- ğŸ Python
- ğŸ“¦ OpenCV / Tesseract / PyTorch (depending on model used)
- ğŸ§  OCR Model (custom/pretrained)
- ğŸ–¥ï¸ System performance tracking tools (FPS calculator, timer utilities)

---

## ğŸ“ Repository Structure

